# Capstone_Project

## Segment 1
1. Topic: 
-    Vietnam War ( US Aircraft losses )
2. Reason why we selected their topic: 
-    As a team we selected this topic becuase of our shared interest in historical events as well as due to the nature of the dataset itself; our source provided many features that we thought would make for an interesting story once we applied machine learning. We figured this dataset would also be a solid foundation for us to showcase many of the skills we have learned throughout the course.
3. Description of our source of data: 
-    Our data sources are two websites dedicated to military aviation research, those being (https://www.aviationarchaeology.com/index.asp) and (https://www.vietnamairlosses.com/index.php). Each provided data on aircraft losses, such as crash date, pilot status, base stationed, target, squadron, aircraft type, where the aircraft was hit, defense utilized, etc. We obtained the data by scraping the web pages on both sites as the data each held offered slightly different features that we could potentially use. 
4. Questions we hope to answer with the data: 
-    A major question we hope to answer with the dataset we have compiled is what feature(s) best indicate a pilot status post crash, specifically what was the greatest determinant of pilot recovery vs pilot KIA.
5. Description of our communication protocols:
-   Our Team's communication was mainly through a slack channel that we created but we also used a iMessage group chat as an informal means of communication. We also planned several zoom calls in order to coordinate objectives between each other, for instance we established roles and made a plan for what we would accomplish by our next meeting.

## Ben's Addition Begin:
### Technologies Used

### Data Cleaning and Analysis:
The data will first be pulled from its original online source using the webscraping library BeautifulSoup. The dataframe creation, data, cleaning, organizating, and all exploratory analysis will be completed in Pandas.

### Database Storage:
Our database will be created in PostgreSQL. The sqlalchemy module will be used to pull in data from our python ETL file to Postgres and from Postgres to our machine learning python file.

### Machine Learning:
SciKitLearn is the ML libary we'll use in Python to create our model. (NEED INFO FROM SAMUEL ON TYPE OF MODEL AND OUR TRAINING AND TESTING SETUP)

### Dashboard:
We will use Tableau to create an interactive dashboard and story of our findings. This will be hosted on Tableau Public.
## End of Ben's Addition

## Contributors

Thanks to the following people who have contributed to this project:

* [@bfox87](https://github.com/bfox87) 
* [@CPotts82](https://github.com/CPotts82) 
* [@samboest](https://github.com/samboest) 

You might want to consider using something like the [All Contributors](https://github.com/all-contributors/all-contributors) specification and its [emoji key](https://allcontributors.org/docs/en/emoji-key).

## Contact

If you want to contact me you can reach me at <your_email@address.com>.
